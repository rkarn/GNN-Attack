{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7e26c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://arshren.medium.com/different-graph-neural-network-implementation-using-pytorch-geometric-23f5bf2f3e9f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbcc5fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch_geometric\n",
    "from torch.nn import Parameter\n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "import networkx as nx\n",
    "import urllib.request\n",
    "import tarfile\n",
    "from torch_geometric.nn import GraphSAGE\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.utils import to_networkx\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cd3e11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the PubMMed dataset\n",
    "dataset = Planetoid(root='.', name=\"Pubmed\")\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2cd54be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Pubmed()\n",
      "-------------------\n",
      "Number of graphs: 1\n",
      "Number of nodes and features: torch.Size([19717, 500])\n",
      "Number of features: 500\n",
      "Number of classes: 3\n"
     ]
    }
   ],
   "source": [
    "# view the dataset details\n",
    "# Print information about the dataset\n",
    "print(f'Dataset: {dataset}')\n",
    "print('-------------------')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of nodes and features: {data.x.shape}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a782b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Graph:\n",
      "------\n",
      "Training nodes: 60\n",
      "Evaluation nodes: 500\n",
      "Test nodes: 1000\n",
      "Edges are directed: False\n",
      "Graph has isolated nodes: False\n",
      "Graph has loops: False\n"
     ]
    }
   ],
   "source": [
    "# Print information about the graph\n",
    "print(f'\\nGraph:')\n",
    "print('------')\n",
    "print(f'Training nodes: {sum(data.train_mask).item()}')\n",
    "print(f'Evaluation nodes: {sum(data.val_mask).item()}')\n",
    "print(f'Test nodes: {sum(data.test_mask).item()}')\n",
    "print(f'Edges are directed: {data.is_directed()}')\n",
    "print(f'Graph has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Graph has loops: {data.has_self_loops()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28b69b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf675232",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = NeighborLoader(\n",
    "    data,\n",
    "    num_neighbors=[5, 10],\n",
    "    batch_size=16,\n",
    "    input_nodes=data.train_mask,\n",
    ")\n",
    "'''\n",
    "Graph Convolutional Network\n",
    "GCN takes graphs as an input and applies convolution operations over the graph\n",
    "'''\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "    def forward(self, x, edge_index):\n",
    "        # x: Node feature matrix \n",
    "        # edge_index: Graph connectivity matrix \n",
    "        #x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x, F.log_softmax(x, dim=1)\n",
    "    \n",
    "'''\n",
    "Graph SAGE: SAmpling and aggreGatE, \n",
    "Samples only a subset of neighboring nodes at different depth layers, \n",
    "and then the aggregator takes neighbors of the previous layers and aggregates them\n",
    "'''\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "  \"\"\"GraphSAGE\"\"\"\n",
    "  def __init__(self, dim_in, dim_h, dim_out):\n",
    "    super().__init__()\n",
    "    self.sage1 = SAGEConv(dim_in, dim_h*2)\n",
    "    self.sage2 = SAGEConv(dim_h*2, dim_h)\n",
    "    self.sage3 = SAGEConv(dim_h, dim_out)\n",
    "    self.optimizer = torch.optim.Adam(self.parameters(),\n",
    "                                      lr=0.01,\n",
    "                                      weight_decay=5e-4)\n",
    "\n",
    "  def forward(self, x, edge_index):\n",
    "    h = self.sage1(x, edge_index)\n",
    "    h = torch.relu(h)\n",
    "    h = F.dropout(h, p=0.5, training=self.training)\n",
    "    h = self.sage2(h, edge_index)\n",
    "    h = torch.relu(h)\n",
    "    h = F.dropout(h, p=0.2, training=self.training)\n",
    "    h = self.sage3(h, edge_index)\n",
    "    return h, F.log_softmax(h, dim=1)\n",
    "'''\n",
    "GAT- uses Attention stratgey\n",
    "compute the hidden representations of each node in the Graph by attending \n",
    "over its neighbors using a self-attention strategy\n",
    "'''\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GAT, self).__init__()\n",
    "        self.hid = 8\n",
    "        self.in_head = 8\n",
    "        self.out_head = 1\n",
    "        \n",
    "        self.conv1 = GATConv(dataset.num_features, self.hid, heads=self.in_head, dropout=0.6)\n",
    "        self.conv2 = GATConv(self.hid*self.in_head, dataset.num_classes, concat=False,\n",
    "                             heads=self.out_head, dropout=0.6)\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "\n",
    "    def forward(self,x, edge_index):\n",
    "        \n",
    "        # Dropout before the GAT layer is used to avoid overfitting\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x,F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "def accuracy(pred_y, y):\n",
    "    \"\"\"Calculate accuracy.\"\"\"\n",
    "    return ((pred_y == y).sum() / len(y)).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f8b3b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, epochs):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = model.optimizer\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs+1):\n",
    "      total_loss = 0\n",
    "      acc = 0\n",
    "      val_loss = 0\n",
    "      val_acc = 0\n",
    "\n",
    "      # Train on batches\n",
    "      for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        _, out = model(batch.x, batch.edge_index)\n",
    "        loss = criterion(out[batch.train_mask], batch.y[batch.train_mask])\n",
    "        total_loss += loss\n",
    "        acc += accuracy(out[batch.train_mask].argmax(dim=1), \n",
    "                        batch.y[batch.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Validation\n",
    "        val_loss += criterion(out[batch.val_mask], batch.y[batch.val_mask])\n",
    "        val_acc += accuracy(out[batch.val_mask].argmax(dim=1), \n",
    "                            batch.y[batch.val_mask])\n",
    "\n",
    "      # Print metrics every 10 epochs\n",
    "      if(epoch % 10 == 0):\n",
    "          print(f'Epoch {epoch:>3} | Train Loss: {total_loss/len(train_loader):.3f} '\n",
    "                f'| Train Acc: {acc/len(train_loader)*100:>6.2f}% | Val Loss: '\n",
    "                f'{val_loss/len(train_loader):.2f} | Val Acc: '\n",
    "                f'{val_acc/len(train_loader)*100:.2f}%')\n",
    "          \n",
    "def test(model, data):\n",
    "    \"\"\"Evaluate the model on test set and print the accuracy score.\"\"\"\n",
    "    model.eval()\n",
    "    _, out = model(data.x, data.edge_index)\n",
    "    acc = accuracy(out.argmax(dim=1)[data.test_mask], data.y[data.test_mask])\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf3b958c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 88648]), torch.Size([19717, 500]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index.shape, data.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3dd2ffbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(500, 16)\n",
      "  (conv2): GCNConv(16, 3)\n",
      ")\n",
      "Epoch   0 | Train Loss: 1.110 | Train Acc:  32.25% | Val Loss: 1.10 | Val Acc: 32.64%\n",
      "Epoch  10 | Train Loss: 0.819 | Train Acc:  86.64% | Val Loss: 0.80 | Val Acc: 83.33%\n",
      "Epoch  20 | Train Loss: 0.536 | Train Acc:  91.28% | Val Loss: 0.66 | Val Acc: 82.77%\n",
      "Epoch  30 | Train Loss: 0.352 | Train Acc:  92.97% | Val Loss: 0.52 | Val Acc: 76.25%\n",
      "Epoch  40 | Train Loss: 0.241 | Train Acc:  95.04% | Val Loss: 0.57 | Val Acc: 83.75%\n",
      "Epoch  50 | Train Loss: 0.207 | Train Acc:  97.92% | Val Loss: 0.41 | Val Acc: 83.04%\n",
      "Epoch  60 | Train Loss: 0.149 | Train Acc:  98.53% | Val Loss: 0.25 | Val Acc: 90.62%\n",
      "Epoch  70 | Train Loss: 0.117 | Train Acc:  98.53% | Val Loss: 0.23 | Val Acc: 95.83%\n",
      "Epoch  80 | Train Loss: 0.102 | Train Acc:  98.53% | Val Loss: 0.47 | Val Acc: 85.42%\n",
      "Epoch  90 | Train Loss: 0.113 | Train Acc: 100.00% | Val Loss: 0.44 | Val Acc: 86.32%\n",
      "Epoch 100 | Train Loss: 0.100 | Train Acc: 100.00% | Val Loss: 0.27 | Val Acc: 91.29%\n",
      "Epoch 110 | Train Loss: 0.091 | Train Acc:  98.53% | Val Loss: 0.66 | Val Acc: 71.79%\n",
      "Epoch 120 | Train Loss: 0.082 | Train Acc: 100.00% | Val Loss: 0.33 | Val Acc: 86.46%\n",
      "Epoch 130 | Train Loss: 0.075 | Train Acc: 100.00% | Val Loss: 0.34 | Val Acc: 84.44%\n",
      "Epoch 140 | Train Loss: 0.082 | Train Acc: 100.00% | Val Loss: 0.74 | Val Acc: 68.75%\n",
      "Epoch 150 | Train Loss: 0.071 | Train Acc: 100.00% | Val Loss: 0.34 | Val Acc: 88.31%\n",
      "Epoch 160 | Train Loss: 0.102 | Train Acc:  98.61% | Val Loss: 0.61 | Val Acc: 79.19%\n",
      "Epoch 170 | Train Loss: 0.052 | Train Acc: 100.00% | Val Loss: 0.46 | Val Acc: 77.78%\n",
      "Epoch 180 | Train Loss: 0.040 | Train Acc: 100.00% | Val Loss: 0.35 | Val Acc: 88.19%\n",
      "Epoch 190 | Train Loss: 0.103 | Train Acc:  97.92% | Val Loss: 0.94 | Val Acc: 60.04%\n",
      "Epoch 200 | Train Loss: 0.065 | Train Acc: 100.00% | Val Loss: 0.50 | Val Acc: 80.12%\n",
      "\n",
      "GCN test accuracy: 77.10%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create GCN\n",
    "gcn = GCN().to(device)\n",
    "print(gcn)\n",
    "\n",
    "# Train GCN\n",
    "train(gcn, dataset, 200)\n",
    "\n",
    "# Test GCN\n",
    "print(f'\\nGCN test accuracy: {test(gcn, data)*100:.2f}%\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a6a6ae53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "     Layer.Parameter         Param Tensor Shape         Param #\n",
      "----------------------------------------------------------------\n",
      "          conv1.bias                       [16]              16\n",
      "    conv1.lin.weight                  [16, 500]            8000\n",
      "          conv2.bias                        [3]               3\n",
      "    conv2.lin.weight                    [3, 16]              48\n",
      "----------------------------------------------------------------\n",
      "Total params: 8067\n",
      "Trainable params: 8067\n",
      "Non-trainable params: 0\n"
     ]
    }
   ],
   "source": [
    "def gnn_model_summary(model):\n",
    "    \n",
    "    model_params_list = list(model.named_parameters())\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    line_new = \"{:>20}  {:>25} {:>15}\".format(\"Layer.Parameter\", \"Param Tensor Shape\", \"Param #\")\n",
    "    print(line_new)\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    for elem in model_params_list:\n",
    "        p_name = elem[0] \n",
    "        p_shape = list(elem[1].size())\n",
    "        p_count = torch.tensor(elem[1].size()).prod().item()\n",
    "        line_new = \"{:>20}  {:>25} {:>15}\".format(p_name, str(p_shape), str(p_count))\n",
    "        print(line_new)\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    total_params = sum([param.nelement() for param in model.parameters()])\n",
    "    print(\"Total params:\", total_params)\n",
    "    num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(\"Trainable params:\", num_trainable_params)\n",
    "    print(\"Non-trainable params:\", total_params - num_trainable_params)\n",
    "gnn_model_summary(gcn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69e59943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphSAGE(\n",
      "  (sage1): SAGEConv(500, 128, aggr=mean)\n",
      "  (sage2): SAGEConv(128, 64, aggr=mean)\n",
      "  (sage3): SAGEConv(64, 3, aggr=mean)\n",
      ")\n",
      "Epoch   0 | Train Loss: 1.175 | Train Acc:  22.70% | Val Loss: 1.13 | Val Acc: 16.67%\n",
      "Epoch  10 | Train Loss: 0.012 | Train Acc: 100.00% | Val Loss: 0.47 | Val Acc: 77.43%\n",
      "Epoch  20 | Train Loss: 0.007 | Train Acc: 100.00% | Val Loss: 0.70 | Val Acc: 74.17%\n",
      "Epoch  30 | Train Loss: 0.072 | Train Acc:  97.22% | Val Loss: 0.64 | Val Acc: 74.90%\n",
      "Epoch  40 | Train Loss: 0.004 | Train Acc: 100.00% | Val Loss: 0.38 | Val Acc: 88.06%\n",
      "Epoch  50 | Train Loss: 0.004 | Train Acc: 100.00% | Val Loss: 0.40 | Val Acc: 83.81%\n",
      "Epoch  60 | Train Loss: 0.008 | Train Acc: 100.00% | Val Loss: 0.62 | Val Acc: 64.91%\n",
      "Epoch  70 | Train Loss: 0.002 | Train Acc: 100.00% | Val Loss: 0.54 | Val Acc: 76.52%\n",
      "Epoch  80 | Train Loss: 0.004 | Train Acc: 100.00% | Val Loss: 0.50 | Val Acc: 70.42%\n",
      "Epoch  90 | Train Loss: 0.007 | Train Acc: 100.00% | Val Loss: 0.73 | Val Acc: 82.08%\n",
      "Epoch 100 | Train Loss: 0.001 | Train Acc: 100.00% | Val Loss: 0.72 | Val Acc: 76.85%\n",
      "Epoch 110 | Train Loss: 0.001 | Train Acc: 100.00% | Val Loss: 0.71 | Val Acc: 78.89%\n",
      "Epoch 120 | Train Loss: 0.013 | Train Acc: 100.00% | Val Loss: 0.79 | Val Acc: 77.12%\n",
      "Epoch 130 | Train Loss: 0.002 | Train Acc: 100.00% | Val Loss: 0.59 | Val Acc: 69.70%\n",
      "Epoch 140 | Train Loss: 0.012 | Train Acc: 100.00% | Val Loss: 0.61 | Val Acc: 81.39%\n",
      "Epoch 150 | Train Loss: 0.004 | Train Acc: 100.00% | Val Loss: 1.10 | Val Acc: 64.86%\n",
      "Epoch 160 | Train Loss: 0.005 | Train Acc: 100.00% | Val Loss: 0.53 | Val Acc: 79.76%\n",
      "Epoch 170 | Train Loss: 0.005 | Train Acc: 100.00% | Val Loss: 0.67 | Val Acc: 68.05%\n",
      "Epoch 180 | Train Loss: 0.002 | Train Acc: 100.00% | Val Loss: 0.58 | Val Acc: 79.34%\n",
      "Epoch 190 | Train Loss: 0.021 | Train Acc:  98.53% | Val Loss: 0.41 | Val Acc: 73.75%\n",
      "Epoch 200 | Train Loss: 0.005 | Train Acc: 100.00% | Val Loss: 0.41 | Val Acc: 88.54%\n",
      "\n",
      "GraphSAGE test accuracy: 76.10%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create GraphSAGE\n",
    "graphsage = GraphSAGE(dataset.num_features, 64, dataset.num_classes).to(device)\n",
    "print(graphsage)\n",
    "\n",
    "# Train GraphSAGE\n",
    "train(graphsage, dataset, 200)\n",
    "\n",
    "# Test GraphSAGE\n",
    "print(f'\\nGraphSAGE test accuracy: {test(graphsage, data)*100:.2f}%\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8318712e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "     Layer.Parameter         Param Tensor Shape         Param #\n",
      "----------------------------------------------------------------\n",
      "  sage1.lin_l.weight                 [128, 500]           64000\n",
      "    sage1.lin_l.bias                      [128]             128\n",
      "  sage1.lin_r.weight                 [128, 500]           64000\n",
      "  sage2.lin_l.weight                  [64, 128]            8192\n",
      "    sage2.lin_l.bias                       [64]              64\n",
      "  sage2.lin_r.weight                  [64, 128]            8192\n",
      "  sage3.lin_l.weight                    [3, 64]             192\n",
      "    sage3.lin_l.bias                        [3]               3\n",
      "  sage3.lin_r.weight                    [3, 64]             192\n",
      "----------------------------------------------------------------\n",
      "Total params: 144963\n",
      "Trainable params: 144963\n",
      "Non-trainable params: 0\n"
     ]
    }
   ],
   "source": [
    "gnn_model_summary(graphsage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ceef79dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAT(\n",
      "  (conv1): GATConv(500, 8, heads=8)\n",
      "  (conv2): GATConv(64, 3, heads=1)\n",
      ")\n",
      "Epoch   0 | Train Loss: 1.162 | Train Acc:  23.07% | Val Loss: 1.12 | Val Acc: 25.19%\n",
      "Epoch  10 | Train Loss: 0.752 | Train Acc:  80.04% | Val Loss: 1.03 | Val Acc: 54.58%\n",
      "Epoch  20 | Train Loss: 0.673 | Train Acc:  80.11% | Val Loss: 1.24 | Val Acc: 46.25%\n",
      "Epoch  30 | Train Loss: 0.662 | Train Acc:  73.38% | Val Loss: 0.83 | Val Acc: 60.00%\n",
      "Epoch  40 | Train Loss: 0.513 | Train Acc:  73.37% | Val Loss: 1.07 | Val Acc: 54.85%\n",
      "Epoch  50 | Train Loss: 0.399 | Train Acc:  86.03% | Val Loss: 0.89 | Val Acc: 64.29%\n",
      "Epoch  60 | Train Loss: 0.476 | Train Acc:  76.87% | Val Loss: 0.79 | Val Acc: 60.12%\n",
      "Epoch  70 | Train Loss: 0.393 | Train Acc:  81.19% | Val Loss: 0.88 | Val Acc: 54.10%\n",
      "Epoch  80 | Train Loss: 0.399 | Train Acc:  84.13% | Val Loss: 0.87 | Val Acc: 59.17%\n",
      "Epoch  90 | Train Loss: 0.341 | Train Acc:  82.54% | Val Loss: 0.67 | Val Acc: 68.75%\n",
      "Epoch 100 | Train Loss: 0.379 | Train Acc:  80.21% | Val Loss: 0.76 | Val Acc: 55.78%\n",
      "Epoch 110 | Train Loss: 0.401 | Train Acc:  81.99% | Val Loss: 0.75 | Val Acc: 45.09%\n",
      "Epoch 120 | Train Loss: 0.444 | Train Acc:  75.49% | Val Loss: 0.56 | Val Acc: 68.61%\n",
      "Epoch 130 | Train Loss: 0.467 | Train Acc:  78.99% | Val Loss: 0.95 | Val Acc: 54.38%\n",
      "Epoch 140 | Train Loss: 0.392 | Train Acc:  87.42% | Val Loss: 0.86 | Val Acc: 40.42%\n",
      "Epoch 150 | Train Loss: 0.282 | Train Acc:  87.96% | Val Loss: 0.59 | Val Acc: 78.27%\n",
      "Epoch 160 | Train Loss: 0.285 | Train Acc:  86.40% | Val Loss: 1.19 | Val Acc: 74.60%\n",
      "Epoch 170 | Train Loss: 0.349 | Train Acc:  81.10% | Val Loss: 0.81 | Val Acc: 65.45%\n",
      "Epoch 180 | Train Loss: 0.292 | Train Acc:  83.61% | Val Loss: 1.32 | Val Acc: 61.46%\n",
      "Epoch 190 | Train Loss: 0.349 | Train Acc:  81.78% | Val Loss: 0.90 | Val Acc: 62.50%\n",
      "Epoch 200 | Train Loss: 0.320 | Train Acc:  87.59% | Val Loss: 1.04 | Val Acc: 69.70%\n",
      "\n",
      "Graph Attention Network test accuracy: 78.30%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create GAT\n",
    "gat = GAT().to(device)\n",
    "print(gat)\n",
    "\n",
    "# Train Graph Attention Network\n",
    "train(gat, dataset, 200)\n",
    "\n",
    "# Test GAT\n",
    "print(f'\\nGraph Attention Network test accuracy: {test(gat, data)*100:.2f}%\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8e4ac53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "     Layer.Parameter         Param Tensor Shape         Param #\n",
      "----------------------------------------------------------------\n",
      "       conv1.att_src                  [1, 8, 8]              64\n",
      "       conv1.att_dst                  [1, 8, 8]              64\n",
      "          conv1.bias                       [64]              64\n",
      "conv1.lin_src.weight                  [64, 500]           32000\n",
      "       conv2.att_src                  [1, 1, 3]               3\n",
      "       conv2.att_dst                  [1, 1, 3]               3\n",
      "          conv2.bias                        [3]               3\n",
      "conv2.lin_src.weight                    [3, 64]             192\n",
      "----------------------------------------------------------------\n",
      "Total params: 32393\n",
      "Trainable params: 32393\n",
      "Non-trainable params: 0\n"
     ]
    }
   ],
   "source": [
    "gnn_model_summary(gat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47a6cf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
